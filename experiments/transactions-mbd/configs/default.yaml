seed_everything: 42
num_evaluation_seeds: 3

num_classes: 60
num_classes_plus1: 61
max_time_delta: 20
max_duration: 200
num_downstream_classes: 2

rnn_hidden_size: 1024
rnn_half_hidden_size: 512
rnn_inference_context: 1200
rnn_inference_context_step: 200
rnn_min_length: 256

transformer_hidden_size: 512
transformer_inter_size: 1024
transformer_heads: 4
transformer_layers: 8
transformer_context: 300
transformer_positions: 2000
transformer_dropout: 0.1
transformer_min_length: 4
transformer_cls_token:
  timestamps: -1
  labels: ${num_classes}  # Use final label for CLS.
  currency: 0
  operation_kind: 0
  operation_type: 0
  operation_type_group: 0
  card_type: 0
  ecommerce_flag: 0
  payment_system: 0
  income_flag: 0
  country: 0
  city: 0
  mcc_category: 0
  day_of_week: 0
  hour: 0
  weekofyear: 0
  log_amount: -1
  log_hour_diff: -1
transformer_history_token_frequency: 0.3
transformer_history_token_probability: 0.5
transformer_recmem_chunk_size: 256

logger:
  _target_: pytorch_lightning.loggers.WandbLogger
  project: pretpp-alfabattle-full
  name: ${name}
  save_dir: lightning_logs
model_path: checkpoints/${name}.ckpt
report: results/${name}.yaml
multiseed_report: results/multiseed_${name}.yaml

data_module:
  _target_: hotpp.data.HotppDataModule
  fields:
    - timestamps
    - labels
    - amount
    - event_subtype
    - currency
    - src_type11
    - src_type12
    - dst_type11
    - dst_type12
    - src_type21
    - src_type22
    - src_type31
    - src_type32
  batch_size: 512
  num_workers: 4
  train_params:
    min_required_length: 2
    max_length: 300
  val_params:
    max_length: 300
    position: last
  test_params:
    max_length: 300
    position: last
  #global_target_fields: target
  train_path: data/train.parquet
  val_path: data/test.parquet
  test_path: data/test.parquet

metric: null

nohead:
  _target_: pretpp.nn.IdentityHead
  _partial_: true

head:
  _target_: hotpp.nn.Head
  _partial_: true
  hidden_dims: [128]
  use_batch_norm: true

metric_head:
  _target_: pretpp.nn.MetricHead
  _partial_: true
  hidden_dims: [128]
  head_params:
    use_batch_norm: true

conditional_head:
  _target_: hotpp.nn.ConditionalHead
  _partial_: true
  hidden_dims: [128]
  use_batch_norm: true

metric_conditional_head:
  _target_: pretpp.nn.MetricConditionalHead
  _partial_: true
  hidden_dims: [128, 128]
  head_params:
    use_batch_norm: true

module:
  seq_encoder:
    embedder:
      _target_: hotpp.nn.Embedder
      use_batch_norm: false
      embeddings:
        labels:  # mcc.
          in: ${num_classes}
          out: 24
          clip: true
        event_subtype:
          in: 70
          out: 24
          clip: true
        currency:
          in: 10
          out: 4
          clip: true
        src_type11:
          in: 85
          out: 24
          clip: true
        src_type12:
          in: 380
          out: 24
          clip: true
        dst_type11:
          in: 90
          out: 24
          clip: true
        dst_type12:
          in: 500
          out: 12
          clip: true
        src_type21:  # MY.
          in: 10002
          out: 64
          clip: true
        src_type22:
          in: 90
          out: 24
          clip: true
        src_type31:  # MY.
          in: 2406
          out: 32
          clip: true
        src_type32:
          in: 91
          out: 24
          clip: true
      numeric_values:
        timestamps: identity
        amount: identity
    max_time_delta: ${max_time_delta}
  aggregator:
    _target_: hotpp.nn.LastAggregator
  optimizer_partial:
    _partial_: true
    _target_: torch.optim.Adam
    lr: 0.001
    weight_decay: 0.0
  lr_scheduler_partial:
    _partial_: true
    _target_: torch.optim.lr_scheduler.StepLR
    step_size: 10
    gamma: 0.8
  val_metric: ${metric}
  test_metric: ${metric}

trainer:
  accelerator: cuda
  devices: 1
  max_epochs: 60
  enable_checkpointing: true
  precision: bf16-mixed
  gradient_clip_val: 1  # Increases training stability.
  check_val_every_n_epoch: 3
  model_selection:
    metric: val/loss
    mode: min
