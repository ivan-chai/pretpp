defaults:
  - default
  - default_transformer
  - coles_loss@module.loss
  - _self_

name: coles_transformer

data_module:
  batch_size: 64

module:
  _target_: pretpp.modules.BaseModule
  optimizer_partial:
    lr: 0.001
  lr_scheduler_partial:
    gamma: 0.9025
    step_size: 30
  head_partial:
    _target_: pretpp.nn.NormalizationHead
    _partial_: true
  aggregator:
    _target_: hotpp.nn.LastAggregator
  loss_projection_partial: ${nohead}
trainer:
  max_epochs: 150
  check_val_every_n_epoch: 10
